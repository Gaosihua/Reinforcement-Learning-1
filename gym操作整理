import gym
import numpy as np
# #创建环境
# env = gym.make('CartPole-v0')
# #查看gym中的全部环境
# env_specs = gym.envs.registry.all()
# env_ids = [env_spec.id for env_spec in env_specs]
# print(env_ids)
# #初始化环境
# env.reset()
# #行动
# #step()输入为agent的动作
# #step()输出为observation(state)、reward、done、info
# env.step()
# #随机动作
# action = env.action_space.sample()
# #可视化
# env.render()
# #关闭环境
# env.close()

#实例
env = gym.make('MountainCar-v0')
print('观测空间 = {}'.format(env.observation_space))
print('动作空间 = {}'.format(env.action_space))
print('观测范围 = {} ~ {}'.format(env.observation_space.low,env.observation_space.high))
print('动作数 = {}'.format(env.action_space.n))

#agent
class BespokeAgent():
    def __init__(self,env):
        pass

    def decide(self,observation):
        position,velocity = observation
        lb = min(-0.09 * (position + 0.25) ** 2 + 0.03,0.3 * (position + 0.9) ** 4 - 0.008)
        ub = -0.07 * (position + 0.38) ** 2 + 0.06
        if lb < velocity < ub :
            action = 2
        else:
            action = 0
        return action

    def learn(self,*args):
        pass

agent = BespokeAgent(env)
def play_mountaincar(env,agent,render = False,train = False):
    episode_reward = 0
    observation = env.reset()
    while True:
        if render:
            env.render()
        action = agent.decide(observation)
        next_observation , reward,done,_ = env.step(action)
        episode_reward += reward
        if train:
            agent.learn(observation,action,reward,done)
        if done:
            break
        observation = next_observation
    return episode_reward

episode_rewards = [play_mountaincar(env,agent,render=True) for _ in range(1)]
print('平均回合奖励={}'.format(np.mean(episode_rewards)))
env.close()
